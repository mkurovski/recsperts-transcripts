{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p_qKjHqiRWTK"
   },
   "source": [
    "# How To (automate this)\n",
    "\n",
    "1. Upload episode mp3-file to Google Drive Recsperts' audio folder\n",
    "2. Start this Notebook in Colab and choose GPU as runtime type\n",
    "3. Adapt filename for episode file\n",
    "4. Run the transcription with whisper\n",
    "5. Save pickle file to the Recsperts transcripts folder as `${episode_name}_raw.pkl`\n",
    "6. Run postprocessing to generate `${episode_name}.txt`\n",
    "7. Add, commit and push to git repository: https://github.com/mkurovski/recsperts-transcripts\n",
    "8. Upload to transistor (use API for this): https://developers.transistor.fm/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yA-EF7CW1Q_T"
   },
   "source": [
    "## Using OpenAI Whisper\n",
    "https://github.com/openai/whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ooAWCJNJe-l4",
    "outputId": "dbd16feb-b621-4e07-9f7c-ba237ef9e210"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu focal InRelease                         \u001b[0m\n",
      "Get:3 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]        \n",
      "Get:4 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]      \n",
      "Get:5 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]      \n",
      "Get:6 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
      "Hit:7 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease             \n",
      "Hit:8 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease           \n",
      "Hit:9 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
      "Ign:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  InRelease\n",
      "Hit:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
      "Hit:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  Release\n",
      "Get:13 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2,050 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,295 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [2,952 kB]\n",
      "Get:16 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,479 kB]\n",
      "Fetched 9,115 kB in 2s (4,158 kB/s)\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "21 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "ffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-510\n",
      "Use 'sudo apt autoremove' to remove it.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 21 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "# Colab uses apt because its os is Ubuntu \n",
    "!sudo apt update && sudo apt install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s0V-WmA11M4g",
    "outputId": "5f475a6e-6092-4164-ac3e-b3da271fdc56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for openai-whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "pip install -U -q openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "016vx4Un1Uao",
    "outputId": "e75d3db5-6a85-49c5-c10c-463858377ef1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:           12Gi       768Mi       8.3Gi       1.0Mi       3.6Gi        11Gi\n",
      "Swap:            0B          0B          0B\n",
      "Total:         12Gi       768Mi       8.3Gi\n"
     ]
    }
   ],
   "source": [
    "!free -g -h -t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cb595qmR1acx",
    "outputId": "a747716e-3d16-4a4f-e537-81fbfa24f8f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "from google.colab import drive\n",
    "import whisper\n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PN1qQ7UbfJbA"
   },
   "outputs": [],
   "source": [
    "model_name = \"small.en\"\n",
    "audio_folder = \"/content/drive/My Drive/recsperts/audio\"\n",
    "transcript_folder = \"/content/drive/My Drive/recsperts/transcripts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G4Q5jkvUAZKI",
    "outputId": "f240178e-ede9-4df4-9723-22a79bdeac28"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 461M/461M [01:16<00:00, 6.30MiB/s]\n"
     ]
    }
   ],
   "source": [
    "model = whisper.load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nlUEI2EahCAt"
   },
   "outputs": [],
   "source": [
    "sorted(os.listdir(audio_folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p4dQ7QjGWH8B"
   },
   "source": [
    "## Transcribe Episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jLEY2euRiPis"
   },
   "outputs": [],
   "source": [
    "audio_filename = \"12_recsperts_rishabh_socialnetworks.mp3\"\n",
    "transcript_filename = audio_filename.split(\".\")[0] + \"_raw.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EdrfvAQV2K0J"
   },
   "outputs": [],
   "source": [
    "filepath = os.path.join(audio_folder, audio_filename)\n",
    "result = model.transcribe(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qLPUBistnr2x"
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(transcript_folder, transcript_filename), \"wb\") as file:\n",
    "    pickle.dump(result, file)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
